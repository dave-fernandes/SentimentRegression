{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing for Sentiment Analysis\n",
    "\n",
    "> Copyright 2019 Dave Fernandes. All Rights Reserved.\n",
    "> \n",
    "> Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "> you may not use this file except in compliance with the License.\n",
    "> You may obtain a copy of the License at\n",
    ">\n",
    "> http://www.apache.org/licenses/LICENSE-2.0\n",
    ">  \n",
    "> Unless required by applicable law or agreed to in writing, software\n",
    "> distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "> See the License for the specific language governing permissions and\n",
    "> limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data files can be downloaded from: https://www.kaggle.com/snap/amazon-fine-food-reviews/version/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "BASE_PATH = './data'\n",
    "TRAIN_TEXT = 'train_text'\n",
    "TRAIN_SUMMARY = 'train_summary.txt'\n",
    "TEST_TEXT = 'test_text.txt'\n",
    "TEST_SUMMARY = 'test_summary.txt'\n",
    "\n",
    "def txt_path(filename):\n",
    "    return os.path.join(BASE_PATH, filename + '.txt')\n",
    "\n",
    "def rec_path(filename):\n",
    "    return os.path.join(BASE_PATH, filename + '.tfrecords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean review content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEWS_CSV = './data/amazon-fine-food-reviews/Reviews.csv'\n",
    "\n",
    "reviews = pd.read_csv(REVIEWS_CSV)\n",
    "print('Initial count:', reviews.shape)\n",
    "\n",
    "reviews.drop(['Id', 'ProfileName', 'Time'], axis=1, inplace=True)\n",
    "reviews.dropna(axis=0, inplace=True)\n",
    "print('Has all data:', reviews.shape)\n",
    "\n",
    "reviews.drop_duplicates(subset=['ProductId', 'UserId'], keep='first', inplace=True)\n",
    "reviews.drop(['ProductId', 'UserId'], axis=1, inplace=True)\n",
    "print('No duplicates:', reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the scores\n",
    "- Scores at the extremes should be equally represented.\n",
    "- Somewhat lower counts for middle scores is OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced = None\n",
    "for score in range(1, 6):\n",
    "    score_group = reviews[reviews['Score'] == score]\n",
    "    \n",
    "    if score == 1:\n",
    "        balanced = score_group\n",
    "        max_count = balanced.shape[0]\n",
    "    else:\n",
    "        if score_group.shape[0] > max_count:\n",
    "            score_group = score_group.sample(max_count)\n",
    "        balanced = pd.concat([balanced, score_group], axis=0)\n",
    "\n",
    "del reviews\n",
    "print(balanced.groupby('Score').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FRACTION = 0.2\n",
    "\n",
    "shuffled = balanced.sample(frac=1, axis=0)\n",
    "del balanced\n",
    "\n",
    "n = int(shuffled.shape[0] * TEST_FRACTION)\n",
    "test_frame = shuffled[0:n]\n",
    "train_frame = shuffled[n:-1]\n",
    "del shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save intermediate text files for processing into BERT feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_column(column, file_path):\n",
    "    def clean_html(s):\n",
    "        clean_fn = re.compile('<.*?>')\n",
    "        return re.sub(clean_fn, '', s)\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        text_list = column.apply(clean_html).values\n",
    "\n",
    "        for item in text_list:\n",
    "            file.write(item)\n",
    "            file.write('\\n')\n",
    "\n",
    "write_column(train_frame['Text'], txt_path(TRAIN_TEXT))\n",
    "write_column(train_frame['Summary'], txt_path(TRAIN_SUMMARY))\n",
    "write_column(test_frame['Text'], txt_path(TEST_TEXT))\n",
    "write_column(test_frame['Summary'], txt_path(TEST_SUMMARY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save numerical columns in a TFRecord file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALUES_TEST = 'values_test'\n",
    "VALUES_TRAIN = 'values_train'\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _float_vector_feature(values):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=values))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return _float_vector_feature([value])\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _string_feature(value):\n",
    "    return _bytes_feature(value.encode('utf-8'))\n",
    "\n",
    "def write_values(filename, data_frame):\n",
    "    with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "        for index, row in data_frame.iterrows():\n",
    "            score = row['Score']\n",
    "            votes = row['HelpfulnessDenominator']\n",
    "            upvotes = row['HelpfulnessNumerator']\n",
    "            helpfulness = float(upvotes) / float(votes) if votes > 0 else 0.0\n",
    "\n",
    "            example = tf.train.Example(\n",
    "                features=tf.train.Features(\n",
    "                    feature={\n",
    "                        'score': _int64_feature(score),\n",
    "                        'votes': _int64_feature(votes),\n",
    "                        'helpfulness': _float_feature(helpfulness),\n",
    "                        }))\n",
    "            writer.write(example.SerializeToString())\n",
    "        \n",
    "write_values(rec_path(VALUES_TEST), test_frame)\n",
    "write_values(rec_path(VALUES_TRAIN), train_frame)\n",
    "del test_frame\n",
    "del train_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First download the BERT model from: https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "- Unzip this file into the same directory as the `extract_features.py` script.\n",
    "- Either run the feature extractor from the cell below; or,\n",
    "- You can also run it from the command line: (you will have to repeat this for each of the 4 text files to be processed)\n",
    "```\n",
    "python extract_features.py \\\n",
    "    --input_file=./data/train_text.txt \\\n",
    "    --output_file=./data/train_text.tfrecord \\\n",
    "    --bert_model_dir=./uncased_L-12_H-768_A-12\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_features import extract\n",
    "MODEL_DIR = './uncased_L-12_H-768_A-12'\n",
    "\n",
    "extract(input_file=txt_path(TEST_TEXT), output_file=rec_path(TEST_TEXT), bert_model_dir=MODEL_DIR)\n",
    "extract(input_file=txt_path(TEST_SUMMARY), output_file=rec_path(TEST_SUMMARY), bert_model_dir=MODEL_DIR)\n",
    "extract(input_file=txt_path(TRAIN_TEXT), output_file=rec_path(TRAIN_TEXT), bert_model_dir=MODEL_DIR)\n",
    "extract(input_file=txt_path(TRAIN_SUMMARY), output_file=rec_path(TRAIN_SUMMARY), bert_model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "Run the `Regression.ipynb` notebook next..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
