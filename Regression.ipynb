{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis for Sentiment\n",
    "\n",
    "> Copyright 2019 Dave Fernandes. All Rights Reserved.\n",
    "> \n",
    "> Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "> you may not use this file except in compliance with the License.\n",
    "> You may obtain a copy of the License at\n",
    ">\n",
    "> http://www.apache.org/licenses/LICENSE-2.0\n",
    ">  \n",
    "> Unless required by applicable law or agreed to in writing, software\n",
    "> distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "> See the License for the specific language governing permissions and\n",
    "> limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook performs regression to predict sentiment and helpfulness scores from text reviews.\n",
    "- Data for this analysis should be prepared using the `Preprocessing.ipynb` notebook from this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "MODEL_DIR = './data/Regression'\n",
    "INPUT_DIR = './data/TFRecords'\n",
    "\n",
    "TRAIN_REVIEW = 'train_text_512'\n",
    "TRAIN_SUMMARY = 'train_summary'\n",
    "TRAIN_TEXT = TRAIN_REVIEW\n",
    "TRAIN_SCORES = 'train_values'\n",
    "\n",
    "TEST_REVIEW = 'test_text_512'\n",
    "TEST_SUMMARY = 'test_summary'\n",
    "TEST_TEXT = TEST_REVIEW\n",
    "TEST_SCORES = 'test_values'\n",
    "\n",
    "def rec_path(filename):\n",
    "    return os.path.join(INPUT_DIR, filename + '.tfrec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping function for scores dataset\n",
    "- Includes normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_score_record(example):\n",
    "    # Features in scores TFRecord file\n",
    "    F_SCORE = 'score'              # Review score (1-5)\n",
    "    F_VOTES = 'votes'              # Number of up/down votes\n",
    "    F_HELPFULNESS  = 'helpfulness' # Fraction of up-votes\n",
    "\n",
    "    features_desc = {\n",
    "        F_SCORE: tf.FixedLenFeature([], tf.int64),\n",
    "        F_VOTES: tf.FixedLenFeature([], tf.int64),\n",
    "        F_HELPFULNESS: tf.FixedLenFeature([], tf.float32),\n",
    "        }\n",
    "    features = tf.parse_single_example(example, features=features_desc)\n",
    "    \n",
    "    score = tf.to_float(features[F_SCORE])\n",
    "    votes = features[F_VOTES]\n",
    "    helpfulness = features[F_HELPFULNESS]\n",
    "    \n",
    "    # Normalize to zero mean and unit range\n",
    "    normed_score = (score - 3.0) * 0.5\n",
    "    \n",
    "    return normed_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping function for review text dataset\n",
    "- BERT feature vectors for each review or summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_VECTOR_LENGTH = 768*4\n",
    "FEATURE_VECTOR_COUNT = 1\n",
    "\n",
    "def parse_review_record(example):\n",
    "    # Features in reviews TFRecord file\n",
    "    F_LENGTH = 'vector_length' # Length of each feature vector\n",
    "    F_COUNT = 'vector_count'   # Count of feature vectors in list\n",
    "    F_VECTORS  = 'vector_list' # List of feature vectors\n",
    "\n",
    "    features_desc = {\n",
    "        F_LENGTH: tf.FixedLenFeature([], tf.int64),\n",
    "        F_COUNT: tf.FixedLenFeature([], tf.int64),\n",
    "        F_VECTORS: tf.FixedLenFeature([FEATURE_VECTOR_COUNT, FEATURE_VECTOR_LENGTH], tf.float32),\n",
    "        }\n",
    "    features = tf.parse_single_example(example, features=features_desc)\n",
    "    \n",
    "    v_length = features[F_LENGTH]\n",
    "    v_count = features[F_COUNT]\n",
    "    v_list = features[F_VECTORS]\n",
    "    \n",
    "    return {'news_embedding': v_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input functions for Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    review_train_set = tf.data.TFRecordDataset([rec_path(TRAIN_TEXT)]).map(parse_review_record)\n",
    "    score_train_set = tf.data.TFRecordDataset([rec_path(TRAIN_SCORES)]).map(parse_score_record)\n",
    "    train_set = tf.data.Dataset.zip((review_train_set, score_train_set)).repeat().shuffle(10000).batch(200)\n",
    "    return train_set\n",
    "\n",
    "PLOT_BATCH_SIZE = 1000\n",
    "PLOT_BATCH_COUNT = 5\n",
    "PLOT_POINT_COUNT = PLOT_BATCH_SIZE * PLOT_BATCH_COUNT\n",
    "\n",
    "def train_plot_input_fn():\n",
    "    review_train_set = tf.data.TFRecordDataset([rec_path(TRAIN_TEXT)]).map(parse_review_record)\n",
    "    score_train_set = tf.data.TFRecordDataset([rec_path(TRAIN_SCORES)]).map(parse_score_record)\n",
    "    train_set = tf.data.Dataset.zip((review_train_set, score_train_set)).batch(PLOT_BATCH_SIZE).take(PLOT_BATCH_COUNT)\n",
    "    return train_set\n",
    "\n",
    "def test_plot_input_fn():\n",
    "    review_train_set = tf.data.TFRecordDataset([rec_path(TEST_TEXT)]).map(parse_review_record)\n",
    "    score_train_set = tf.data.TFRecordDataset([rec_path(TEST_SCORES)]).map(parse_score_record)\n",
    "    test_set = tf.data.Dataset.zip((review_train_set, score_train_set)).batch(PLOT_BATCH_SIZE).take(PLOT_BATCH_COUNT)\n",
    "    return test_set\n",
    "\n",
    "def test_input_fn():\n",
    "    review_train_set = tf.data.TFRecordDataset([rec_path(TEST_TEXT)]).map(parse_review_record)\n",
    "    score_train_set = tf.data.TFRecordDataset([rec_path(TEST_SCORES)]).map(parse_score_record)\n",
    "    test_set = tf.data.Dataset.zip((review_train_set, score_train_set)).batch(1000)\n",
    "    return test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model\n",
    "This model is for regression against aggregated scores. It is currently unused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_model_fn(features, labels, mode, params):\n",
    "    current_layer = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    current_layer = tf.expand_dims(tf.layers.flatten(current_layer, name='flatten_input'), -1)\n",
    "    \n",
    "    for i, units in enumerate(params['conv_filters']):\n",
    "        if i == 0:\n",
    "            kernel_size = FEATURE_VECTOR_LENGTH,\n",
    "            strides = FEATURE_VECTOR_LENGTH,\n",
    "        else:\n",
    "            kernel_size = 1,\n",
    "            strides = 1,\n",
    "            \n",
    "        current_layer = tf.layers.conv1d(current_layer,\n",
    "            name='conv1d_' + str(i+1),\n",
    "            filters=units,\n",
    "            data_format='channels_last',\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding='valid',\n",
    "            kernel_initializer=tf.glorot_normal_initializer(),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.01),\n",
    "            bias_regularizer=tf.keras.regularizers.l2(l=0.01),\n",
    "            activation=tf.nn.tanh)\n",
    "\n",
    "    current_layer = tf.layers.max_pooling1d(current_layer,\n",
    "        pool_size=FEATURE_VECTOR_COUNT,\n",
    "        strides=1,\n",
    "        padding='valid',\n",
    "        data_format='channels_last')\n",
    "\n",
    "    current_layer = tf.layers.flatten(current_layer)\n",
    "    \n",
    "    for i, units in enumerate(params['hidden_units']):\n",
    "        current_layer = tf.layers.dense(current_layer,\n",
    "            name='dense_' + str(i+1),\n",
    "            units=units,\n",
    "            kernel_initializer=tf.glorot_normal_initializer(),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.01),\n",
    "            bias_regularizer=tf.keras.regularizers.l2(l=0.01),\n",
    "            activation=tf.nn.tanh)\n",
    "\n",
    "    regression_layer = tf.layers.dense(current_layer,\n",
    "        name='linear_output',\n",
    "        units=REGRESSION_LABEL_COUNT,\n",
    "        kernel_initializer=tf.glorot_normal_initializer(),\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l=0.01),\n",
    "        bias_regularizer=tf.keras.regularizers.l2(l=0.01),\n",
    "        activation=None)\n",
    "\n",
    "    # For prediction, exit here\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'predictions': regression_layer,\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # For training and evaluation, compute the loss (MSE)\n",
    "    loss = tf.losses.mean_squared_error(labels, regression_layer)\n",
    "\n",
    "    abs_error = tf.metrics.mean_tensor(tf.reduce_mean(tf.abs(labels - regression_layer), axis=0))\n",
    "    metrics = {'abs_error': abs_error}\n",
    "    tf.summary.tensor_summary('abs_error', abs_error)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    # For training...\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.01)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column('news_embedding', [FEATURE_VECTOR_COUNT, FEATURE_VECTOR_LENGTH])]\n",
    "\n",
    "\"\"\"\n",
    "regressor = tf.estimator.Estimator(\n",
    "    model_fn=news_model_fn,\n",
    "    model_dir=MODEL_DIR,\n",
    "    params={\n",
    "        'feature_columns': feature_columns,\n",
    "        'conv_filters': [300, 30],\n",
    "        'hidden_units': [30, 8],\n",
    "    })\n",
    "\"\"\"\n",
    "\n",
    "regressor = tf.estimator.DNNRegressor(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[300, 30, 8],\n",
    "    model_dir=MODEL_DIR,\n",
    "    label_dimension=1,\n",
    "    activation_fn=tf.nn.relu,\n",
    "    optimizer='Adagrad',\n",
    "    batch_norm=False,\n",
    "    dropout=None\n",
    ")\n",
    "\n",
    "regressor.train(train_input_fn, steps=6000)\n",
    "\n",
    "info = regressor.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fn = test_plot_input_fn\n",
    "REGRESSION_LABEL_COUNT = 1\n",
    "\n",
    "predictions = regressor.predict(input_fn=dataset_fn)\n",
    "dataset = dataset_fn()\n",
    "actual = None\n",
    "predicted = []\n",
    "\n",
    "for i, value in enumerate(predictions):\n",
    "    predicted.append(value['predictions'])\n",
    "\n",
    "j = 0\n",
    "for x, y in dataset:\n",
    "    batch = y.numpy()\n",
    "    noise = np.random.normal(0.0, 0.15, np.size(batch))\n",
    "    #noise = np.random.random(np.size(batch)) - 0.5\n",
    "    batch = batch + np.reshape(noise, np.shape(batch))\n",
    "    \n",
    "    if j == 0:\n",
    "        actual = batch\n",
    "    else:\n",
    "        actual = np.concatenate((actual, batch), axis=0)\n",
    "        \n",
    "    j += np.shape(batch)[0]\n",
    "\n",
    "actual = np.reshape(actual, (len(actual), REGRESSION_LABEL_COUNT))\n",
    "predicted = np.reshape(predicted, (len(predicted), REGRESSION_LABEL_COUNT))\n",
    "\n",
    "titles = ['Open', 'Close', 'High', 'Low']\n",
    "\n",
    "for offset in range(REGRESSION_LABEL_COUNT):\n",
    "    maximum = max(actual[:, offset] + predicted[:, offset])\n",
    "    minimum = min(actual[:, offset] + predicted[:, offset])\n",
    "    plt.plot([minimum,maximum],[minimum,maximum])\n",
    "    \n",
    "    plt.scatter(actual[:, offset], predicted[:, offset], marker='.', s=1)\n",
    "    \n",
    "    plt.ylabel('predicted')\n",
    "    plt.xlabel('actual')\n",
    "    plt.title(titles[offset] + ' Log Ratio')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for offset in range(REGRESSION_LABEL_COUNT):\n",
    "    maximum = max(predicted[:, offset])\n",
    "    minimum = min(predicted[:, offset])\n",
    "    plt.plot([minimum,maximum],[minimum,maximum])\n",
    "    \n",
    "    plt.scatter(actual[:, offset], predicted[:, offset], marker='.', s=1)\n",
    "    \n",
    "    plt.ylabel('predicted')\n",
    "    plt.xlabel('actual')\n",
    "    plt.title(titles[offset] + ' Log Ratio')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
