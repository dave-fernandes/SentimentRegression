{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis for Sentiment\n",
    "\n",
    "> Copyright 2019 Dave Fernandes. All Rights Reserved.\n",
    "> \n",
    "> Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "> you may not use this file except in compliance with the License.\n",
    "> You may obtain a copy of the License at\n",
    ">\n",
    "> http://www.apache.org/licenses/LICENSE-2.0\n",
    ">  \n",
    "> Unless required by applicable law or agreed to in writing, software\n",
    "> distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "> WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "> See the License for the specific language governing permissions and\n",
    "> limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook performs regression to predict sentiment and helpfulness scores from text reviews.\n",
    "- Data for this analysis should be prepared using the `Preprocessing.ipynb` notebook from this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "PREDICT_SCORE = True  # Predicts helpfulness if False\n",
    "\n",
    "MODEL_DIR = './data/Regression' if PREDICT_SCORE else './data/HRegression'\n",
    "INPUT_DIR = './data/TFRecords'\n",
    "PREPROCESSED_DIR = './data'\n",
    "\n",
    "TRAIN_REVIEW = 'train_review'\n",
    "TRAIN_SUMMARY = 'train_summary'\n",
    "TRAIN_SCORES = 'train_scores'\n",
    "\n",
    "TEST_REVIEW = 'test_review'\n",
    "TEST_SUMMARY = 'test_summary'\n",
    "TEST_SCORES = 'test_scores'\n",
    "\n",
    "def txt_path(filename):\n",
    "    return os.path.join(PREPROCESSED_DIR, filename + '.txt')\n",
    "\n",
    "def rec_path(filename):\n",
    "    return os.path.join(INPUT_DIR, filename + '.tfrec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping function for scores dataset\n",
    "- Includes normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_score_record(example):\n",
    "    # Features in scores TFRecord file\n",
    "    F_SCORE = 'score'              # Review score (1-5)\n",
    "    F_VOTES = 'votes'              # Number of up/down votes\n",
    "    F_HELPFULNESS  = 'helpfulness' # Fraction of up-votes\n",
    "\n",
    "    features_desc = {\n",
    "        F_SCORE: tf.FixedLenFeature([], tf.int64),\n",
    "        F_VOTES: tf.FixedLenFeature([], tf.int64),\n",
    "        F_HELPFULNESS: tf.FixedLenFeature([], tf.float32),\n",
    "        }\n",
    "    features = tf.parse_single_example(example, features=features_desc)\n",
    "    \n",
    "    score = tf.to_float(features[F_SCORE])\n",
    "    votes = features[F_VOTES]\n",
    "    helpfulness = features[F_HELPFULNESS]\n",
    "    \n",
    "    # Normalize to zero mean and unit range\n",
    "    normed_score = (score - 3.0) * 0.5\n",
    "    \n",
    "    return normed_score, helpfulness, votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping function for review text dataset\n",
    "- BERT feature vectors for each review or summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_VECTOR_LENGTH = 768*4\n",
    "\n",
    "def parse_review_record(example):\n",
    "    # Features in reviews TFRecord file\n",
    "    F_LENGTH = 'vector_length' # Length of each feature vector\n",
    "    F_COUNT = 'vector_count'   # Count of feature vectors in list\n",
    "    F_VECTORS  = 'vector_list' # List of feature vectors\n",
    "\n",
    "    features_desc = {\n",
    "        F_LENGTH: tf.FixedLenFeature([], tf.int64),\n",
    "        F_COUNT: tf.FixedLenFeature([], tf.int64),\n",
    "        F_VECTORS: tf.FixedLenFeature([1, FEATURE_VECTOR_LENGTH], tf.float32),\n",
    "        }\n",
    "    features = tf.parse_single_example(example, features=features_desc)\n",
    "    \n",
    "    v_length = features[F_LENGTH]\n",
    "    v_count = features[F_COUNT]\n",
    "    v_list = features[F_VECTORS]\n",
    "    \n",
    "    return v_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input functions for Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_VECTOR_COUNT = 2\n",
    "REGRESSION_LABEL_COUNT = 1\n",
    "\n",
    "def combine_records(review_vec, summary_vec, score_tuple):\n",
    "    # Combine feature vectors for review and summary into a matrix\n",
    "    text_embeddings = tf.concat([review_vec, summary_vec], axis=1)\n",
    "    \n",
    "    features = {'text_embeddings': text_embeddings, 'votes': score_tuple[2]}\n",
    "    labels = score_tuple[0] if PREDICT_SCORE else score_tuple[1]\n",
    "    return features, labels\n",
    "\n",
    "def filter_votes(features, labels):\n",
    "    return features['votes'] > 1\n",
    "\n",
    "def combined_dataset(review_file, summary_file, score_file):\n",
    "    review_set = tf.data.TFRecordDataset([rec_path(review_file)]).map(parse_review_record)\n",
    "    summary_set = tf.data.TFRecordDataset([rec_path(summary_file)]).map(parse_review_record)\n",
    "    score_set = tf.data.TFRecordDataset([rec_path(score_file)]).map(parse_score_record)\n",
    "    combined_set = tf.data.Dataset.zip((review_set, summary_set, score_set)).map(combine_records)\n",
    "    \n",
    "    if not PREDICT_SCORE:\n",
    "        combined_set = combined_set.filter(filter_votes)\n",
    "    return combined_set\n",
    "\n",
    "# For training\n",
    "def train_input_fn():\n",
    "    dataset = combined_dataset(TRAIN_REVIEW, TRAIN_SUMMARY, TRAIN_SCORES)\n",
    "    return dataset.repeat().shuffle(20000).batch(200).prefetch(1)\n",
    "\n",
    "# For evaluation and plotting predictions\n",
    "def eval_input_fn():\n",
    "    dataset = combined_dataset(TEST_REVIEW, TEST_SUMMARY, TEST_SCORES)\n",
    "    return dataset.batch(1000).prefetch(1)\n",
    "\n",
    "# Subset of training data for plotting\n",
    "PLOT_BATCH_SIZE = 1000\n",
    "PLOT_BATCH_COUNT = 5\n",
    "PLOT_POINT_COUNT = PLOT_BATCH_SIZE * PLOT_BATCH_COUNT\n",
    "\n",
    "def plot_train_input_fn():\n",
    "    dataset = combined_dataset(TRAIN_REVIEW, TRAIN_SUMMARY, TRAIN_SCORES)\n",
    "    return dataset.batch(PLOT_BATCH_SIZE).take(PLOT_BATCH_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "* The two 3072-element feature vectors are fed into a set of 1D-convolutional layers that process each of the vectors independently, but using the same set of weights. This allows us to reduce the number of parameters in the model while allowing the review text to contribute a different weight from the summary to the final regression value. The number of layers and filters is defined by the `conv_filters` parameter (list of integers).\n",
    "* The output from the last convolutional layer is fed into a fully connected network. The number of layers and hidden units is defined by the `hidden_units` parameter (list of integers).\n",
    "* A final linear layer produces the regression output value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial learning rate\n",
    "INITIAL_LEARNING_RATE = 0.001\n",
    "\n",
    "# Learning rate decay per thousand steps (1.0 = no decay)\n",
    "LR_DECAY_PER_THOUSAND = 0.316\n",
    "\n",
    "def news_model_fn(features, labels, mode, params):\n",
    "    is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    conv_batch_normalize = params['conv_batch_normalize']\n",
    "    fc_batch_normalize = params['fc_batch_normalize']\n",
    "    l2_conv = 0.002 if conv_batch_normalize else 0.01\n",
    "    l2_fc = 0.002 if fc_batch_normalize else 0.01\n",
    "    use_conv_tanh = params['use_conv_tanh']\n",
    "    use_fc_tanh = params['use_fc_tanh']\n",
    "    \n",
    "    current_layer = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    current_layer = tf.expand_dims(tf.layers.flatten(current_layer, name='flatten_input'), -1)\n",
    "    \n",
    "    for i, units in enumerate(params['conv_filters']):\n",
    "        if i == 0:\n",
    "            kernel_size = FEATURE_VECTOR_LENGTH,\n",
    "            strides = FEATURE_VECTOR_LENGTH,\n",
    "        else:\n",
    "            kernel_size = 1,\n",
    "            strides = 1,\n",
    "            \n",
    "        current_layer = tf.layers.conv1d(current_layer,\n",
    "            name='conv1d_' + str(i+1),\n",
    "            filters=units,\n",
    "            data_format='channels_last',\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding='valid',\n",
    "            kernel_initializer=tf.glorot_normal_initializer(),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=l2_conv),\n",
    "            bias_regularizer=tf.keras.regularizers.l2(l=l2_conv),\n",
    "            activation=None)\n",
    "        \n",
    "        if conv_batch_normalize:\n",
    "            current_layer = tf.keras.layers.BatchNormalization(axis=2, scale=use_conv_tanh, renorm=True)(current_layer, training=is_training)\n",
    "        current_layer = tf.keras.activations.tanh(current_layer) if use_conv_tanh else tf.keras.activations.relu(current_layer)\n",
    "\n",
    "    current_layer = tf.layers.flatten(current_layer)\n",
    "    \n",
    "    for i, units in enumerate(params['hidden_units']):\n",
    "        current_layer = tf.layers.dense(current_layer,\n",
    "            name='dense_' + str(i+1),\n",
    "            units=units,\n",
    "            kernel_initializer=tf.glorot_normal_initializer(),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=l2_fc),\n",
    "            bias_regularizer=tf.keras.regularizers.l2(l=l2_fc),\n",
    "            activation=None)\n",
    "\n",
    "        if fc_batch_normalize:\n",
    "            current_layer = tf.keras.layers.BatchNormalization(axis=1, scale=use_fc_tanh, renorm=True)(current_layer, training=is_training)\n",
    "        current_layer = tf.keras.activations.tanh(current_layer) if use_fc_tanh else tf.keras.activations.relu(current_layer)\n",
    "\n",
    "    regression_layer = tf.layers.dense(current_layer,\n",
    "        name='linear_output',\n",
    "        units=REGRESSION_LABEL_COUNT,\n",
    "        kernel_initializer=tf.glorot_normal_initializer(),\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l=0.01),\n",
    "        bias_regularizer=tf.keras.regularizers.l2(l=0.01),\n",
    "        activation=None)\n",
    "\n",
    "    # For prediction, exit here\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'predictions': regression_layer,\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # For training and evaluation, compute the loss (MSE)\n",
    "    labels = tf.reshape(labels, tf.shape(regression_layer))\n",
    "    loss = tf.losses.mean_squared_error(labels, regression_layer)\n",
    "\n",
    "    abs_error = tf.metrics.mean_tensor(tf.reduce_mean(tf.abs(labels - regression_layer), axis=0))\n",
    "    metrics = {'abs_error': abs_error}\n",
    "    tf.summary.tensor_summary('abs_error', abs_error)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    # For training...\n",
    "    global_step = tf.train.get_global_step()\n",
    "    learning_rate = tf.train.exponential_decay(INITIAL_LEARNING_RATE, global_step, 1000, LR_DECAY_PER_THOUSAND)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column('text_embeddings', [FEATURE_VECTOR_COUNT, FEATURE_VECTOR_LENGTH])]\n",
    "\n",
    "regressor = tf.estimator.Estimator(\n",
    "    model_fn=news_model_fn,\n",
    "    model_dir=MODEL_DIR,\n",
    "    params={\n",
    "        'feature_columns': feature_columns,\n",
    "        'conv_filters': [300, 30, 15],\n",
    "        'hidden_units': [30, 8],\n",
    "        'conv_batch_normalize': False,\n",
    "        'fc_batch_normalize': False,\n",
    "        'use_conv_tanh': True,\n",
    "        'use_fc_tanh': True,\n",
    "    })\n",
    "\n",
    "regressor.train(train_input_fn, steps=2000)\n",
    "\n",
    "info = regressor.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_fn = eval_input_fn\n",
    "REGRESSION_LABEL_COUNT = 1\n",
    "\n",
    "predictions = regressor.predict(input_fn=dataset_fn)\n",
    "dataset = dataset_fn()\n",
    "actual = None\n",
    "predicted = []\n",
    "\n",
    "for i, value in enumerate(predictions):\n",
    "    predicted.append(value['predictions'])\n",
    "del predictions\n",
    "\n",
    "j = 0\n",
    "for x, y in dataset:\n",
    "    batch = y.numpy()\n",
    "    sd = 0.1 if PREDICT_SCORE else 0.03\n",
    "    noise = np.random.normal(0.0, sd, np.size(batch))\n",
    "    #noise = np.random.random(np.size(batch)) - 0.5\n",
    "    noisy_actual = batch + np.reshape(noise, np.shape(batch))\n",
    "    \n",
    "    if j == 0:\n",
    "        actual = batch\n",
    "        abscissa = noisy_actual\n",
    "    else:\n",
    "        actual = np.concatenate((actual, batch), axis=0)\n",
    "        abscissa = np.concatenate((abscissa, noisy_actual), axis=0)\n",
    "        \n",
    "    j += np.shape(batch)[0]\n",
    "\n",
    "actual = np.reshape(actual, (len(actual), REGRESSION_LABEL_COUNT))\n",
    "abscissa = np.reshape(abscissa, (len(abscissa), REGRESSION_LABEL_COUNT))\n",
    "predicted = np.reshape(predicted, (len(predicted), REGRESSION_LABEL_COUNT))\n",
    "if PREDICT_SCORE:\n",
    "    actual = actual * 2 + 3\n",
    "    abscissa = abscissa * 2 + 3\n",
    "    predicted = predicted * 2 + 3\n",
    "title = 'Review Score' if PREDICT_SCORE else 'Helpfulness'\n",
    "\n",
    "if PREDICT_SCORE:\n",
    "    plt.plot([0.9, 5.1], [0.9, 5.1])\n",
    "else:\n",
    "    plt.plot([-0.1, 1.1], [-0.1, 1.1])\n",
    "    \n",
    "plt.scatter(abscissa[:PLOT_POINT_COUNT], predicted[:PLOT_POINT_COUNT], marker='.', s=1)\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.title(title)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "These correlation coefficients are useful for comparing different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "#coef, p = stats.spearmanr(actual, predicted)\n",
    "\n",
    "tau, p_tau = stats.kendalltau(actual, predicted)\n",
    "print('Kendall tau:', tau, 'p =', p_tau)\n",
    "\n",
    "r, p_r = stats.pearsonr(actual, predicted)\n",
    "print('Pearson r:', r, 'p =', p_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data deep dive\n",
    "Histogram residuals and save CSV files to explore which reviews scores are not predicted well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import linecache\n",
    "\n",
    "OUT_FILE_PREFIX = './data/Predictions_'\n",
    "\n",
    "if PREDICT_SCORE:\n",
    "    residuals = predicted - actual\n",
    "    sorted_predictions = []\n",
    "    \n",
    "    for i in range(1, 6):\n",
    "        original_index = np.where(actual == i)[0]\n",
    "        res = residuals[original_index]\n",
    "        n, bins, patches = plt.hist(res[:PLOT_POINT_COUNT], 50, (-4, 4))\n",
    "        plt.xlabel('Residual')\n",
    "        plt.title('Actual = ' + str(i))\n",
    "        plt.show()\n",
    "        \n",
    "        sorted_predictions.append(predicted[original_index])\n",
    "        \n",
    "        output_list = []\n",
    "        for index in original_index:\n",
    "            review = linecache.getline(txt_path(TEST_REVIEW), index + 1)\n",
    "            summary = linecache.getline(txt_path(TEST_SUMMARY), index + 1)\n",
    "            output_list.append((np.reshape(predicted[index], ()), summary, review))\n",
    "        \n",
    "        output_list.sort(key=lambda tuple: tuple[0])\n",
    "        \n",
    "        with open(OUT_FILE_PREFIX + str(i) + '.csv','w') as out_file:\n",
    "            csv_file = csv.writer(out_file)\n",
    "            csv_file.writerow(['Predicted', 'Summary','Review'])\n",
    "            \n",
    "            for row in output_list:\n",
    "                csv_file.writerow(row)\n",
    "    \n",
    "    plt.plot([0.9, 5.1], [0.9, 5.1])\n",
    "    plt.boxplot(sorted_predictions, labels=range(1, 6), sym='')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
